{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gabriellegustilo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gabriellegustilo/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(tokenized_list):\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    wn = nltk.WordNetLemmatizer() #you'll need to download wordnet from nltk\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "def lemmatize(in_path, out_path, file):\n",
    "    '''\n",
    "    takes a text file, strips it of punctuation, then tokenizes the data.\n",
    "    After tokenization, the stop words are removed.\n",
    "    Then the lemmas of each word is found and returned as a list.\n",
    "    '''\n",
    "    with open(in_path + '/' + file) as f:\n",
    "        rawData = f.read()\n",
    "        cleanData = remove_punct(rawData)\n",
    "        tokenized = tokenize(cleanData.lower())\n",
    "        text_no_stop = remove_stopwords(tokenized)\n",
    "        text_lemmatized = lemmatizing(text_no_stop)\n",
    "    out_file = file[:-4] + '_lemmatized.txt' #way to create lemmatized file name\n",
    "    with open(out_path + '/' + out_file, \"w\") as output:\n",
    "        for word in text_lemmatized:\n",
    "            output.write(str(word) + '\\n')\n",
    "    #in here for validation\n",
    "    #return lemmatizing(text_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gentlemen of the Senate and Gentlemen of the House of Representatives:\n",
      "\n",
      "I was for some time apprehen\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/gabriellegustilo/Dev/personal/machine_learning/final_project/state-of-the-union-corpus-1989-2017/Adams_1797.txt') as f:\n",
    "    rawData = f.read()\n",
    "    print(rawData[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = '/Users/gabriellegustilo/Dev/personal/machine_learning/final_project/state-of-the-union-corpus-1989-2017'\n",
    "out_path = '/Users/gabriellegustilo/Dev/personal/machine_learning/final_project/state-of-the-union-lemmatized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need this to get the file names...probably more efficient way to do this, but ehhhh...\n",
    "from pathlib import Path\n",
    "path = Path(\"/Users/gabriellegustilo/Dev/personal/machine_learning/final_project/state-of-the-union-corpus-1989-2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files = [i for i in os.listdir(path) if i.endswith(\"txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reagan_1982.txt',\n",
       " 'Roosevelt_1902.txt',\n",
       " 'Wilson_1914.txt',\n",
       " 'Taft_1911.txt',\n",
       " 'Madison_1814.txt',\n",
       " 'Polk_1848.txt',\n",
       " 'Jackson_1836.txt',\n",
       " 'Johnson_1969.txt',\n",
       " 'Hoover_1930.txt',\n",
       " 'Pierce_1854.txt',\n",
       " 'Pierce_1855.txt',\n",
       " 'Hoover_1931.txt',\n",
       " 'Johnson_1968.txt',\n",
       " 'Madison_1815.txt',\n",
       " 'Taft_1910.txt',\n",
       " 'Buren_1837.txt',\n",
       " 'Wilson_1915.txt',\n",
       " 'Roosevelt_1903.txt',\n",
       " 'Reagan_1983.txt',\n",
       " 'Roosevelt_1901.txt',\n",
       " 'Taft_1912.txt',\n",
       " 'Wilson_1917.txt',\n",
       " 'Jackson_1835.txt',\n",
       " 'Pierce_1856.txt',\n",
       " 'Hoover_1932.txt',\n",
       " 'Jackson_1834.txt',\n",
       " 'Madison_1816.txt',\n",
       " 'Wilson_1916.txt',\n",
       " 'Reagan_1984.txt',\n",
       " 'Roosevelt_1904.txt',\n",
       " 'Roosevelt_1938.txt',\n",
       " 'Fillmore_1852.txt',\n",
       " 'Madison_1812.txt',\n",
       " 'Jackson_1830.txt',\n",
       " 'Truman_1949.txt',\n",
       " 'Pierce_1853.txt',\n",
       " 'Truman_1948.txt',\n",
       " 'Jackson_1831.txt',\n",
       " 'Madison_1813.txt',\n",
       " 'Wilson_1913.txt',\n",
       " 'Roosevelt_1939.txt',\n",
       " 'Roosevelt_1905.txt',\n",
       " 'Reagan_1985.txt',\n",
       " 'Harrison_1889.txt',\n",
       " 'Reagan_1987.txt',\n",
       " 'Roosevelt_1907.txt',\n",
       " 'Madison_1811.txt',\n",
       " 'Fillmore_1851.txt',\n",
       " 'Jackson_1833.txt',\n",
       " 'Kennedy_1963.txt',\n",
       " 'Kennedy_1962.txt',\n",
       " 'Jefferson_1808.txt',\n",
       " 'Jackson_1832.txt',\n",
       " 'Fillmore_1850.txt',\n",
       " 'Madison_1810.txt',\n",
       " 'Bush_2008.txt',\n",
       " 'Roosevelt_1906.txt',\n",
       " 'Reagan_1986.txt',\n",
       " 'Monroe_1820.txt',\n",
       " 'Grant_1876.txt',\n",
       " 'Cleveland_1896.txt',\n",
       " 'Lincoln_1863.txt',\n",
       " 'Tyler_1841.txt',\n",
       " 'Clinton_1995.txt',\n",
       " 'Obama_2015.txt',\n",
       " 'Buchanan_1860.txt',\n",
       " 'Obama_2014.txt',\n",
       " 'Trump_2017.txt',\n",
       " 'Clinton_1994.txt',\n",
       " 'Lincoln_1862.txt',\n",
       " 'Buren_1840.txt',\n",
       " 'Monroe_1821.txt',\n",
       " 'Monroe_1823.txt',\n",
       " 'Eisenhower_1959.txt',\n",
       " 'Grant_1875.txt',\n",
       " 'Cleveland_1895.txt',\n",
       " 'Tyler_1842.txt',\n",
       " 'McKinley_1898.txt',\n",
       " 'Clinton_1996.txt',\n",
       " 'Obama_2016.txt',\n",
       " 'Adams_1799.txt',\n",
       " 'Adams_1798.txt',\n",
       " 'Clinton_1997.txt',\n",
       " 'McKinley_1899.txt',\n",
       " 'Johnson_1868.txt',\n",
       " 'Tyler_1843.txt',\n",
       " 'Cleveland_1894.txt',\n",
       " 'Lincoln_1861.txt',\n",
       " 'Grant_1874.txt',\n",
       " 'Eisenhower_1958.txt',\n",
       " 'Monroe_1822.txt',\n",
       " 'Eisenhower_1960.txt',\n",
       " 'Grant_1870.txt',\n",
       " 'Bush_1992.txt',\n",
       " 'Clinton_1993.txt',\n",
       " 'Obama_2013.txt',\n",
       " 'Obama_2012.txt',\n",
       " 'Grant_1871.txt',\n",
       " 'Cleveland_1885.txt',\n",
       " 'Lincoln_1864.txt',\n",
       " 'Coolidge_1928.txt',\n",
       " 'Adams_1825.txt',\n",
       " 'Eisenhower_1961.txt',\n",
       " 'Monroe_1819.txt',\n",
       " 'Adams_1827.txt',\n",
       " 'Cleveland_1893.txt',\n",
       " 'Cleveland_1887.txt',\n",
       " 'Grant_1873.txt',\n",
       " 'Hayes_1877.txt',\n",
       " 'Bush_1991.txt',\n",
       " 'Tyler_1844.txt',\n",
       " 'Obama_2010.txt',\n",
       " 'Buchanan_1859.txt',\n",
       " 'Buchanan_1858.txt',\n",
       " 'Obama_2011.txt',\n",
       " 'Bush_1990.txt',\n",
       " 'McKinley_1900.txt',\n",
       " 'Grant_1872.txt',\n",
       " 'Cleveland_1886.txt',\n",
       " 'Adams_1826.txt',\n",
       " 'Monroe_1818.txt',\n",
       " 'Monroe_1824.txt',\n",
       " 'Roosevelt_1940.txt',\n",
       " 'Coolidge_1926.txt',\n",
       " 'Bush_1989.txt',\n",
       " 'Washington_1790.txt',\n",
       " 'Obama_2009.txt',\n",
       " 'Washington_1791.txt',\n",
       " 'Coolidge_1927.txt',\n",
       " 'Roosevelt_1941.txt',\n",
       " 'Adams_1828.txt',\n",
       " 'Adams_1800.txt',\n",
       " 'Roosevelt_1943.txt',\n",
       " 'Coolidge_1925.txt',\n",
       " 'Cleveland_1888.txt',\n",
       " 'Hayes_1878.txt',\n",
       " 'Washington_1793.txt',\n",
       " 'Buchanan_1857.txt',\n",
       " 'Washington_1792.txt',\n",
       " 'Hayes_1879.txt',\n",
       " 'Grant_1869.txt',\n",
       " 'Coolidge_1924.txt',\n",
       " 'Roosevelt_1942.txt',\n",
       " 'Monroe_1817.txt',\n",
       " 'Harding_1922.txt',\n",
       " 'Eisenhower_1955.txt',\n",
       " 'Ford_1976.txt',\n",
       " 'Johnson_1865.txt',\n",
       " 'Washington_1796.txt',\n",
       " 'Trump_2018.txt',\n",
       " 'Ford_1977.txt',\n",
       " 'Eisenhower_1954.txt',\n",
       " 'Harding_1921.txt',\n",
       " 'Eisenhower_1956.txt',\n",
       " 'Roosevelt_1945.txt',\n",
       " 'Coolidge_1923.txt',\n",
       " 'Ford_1975.txt',\n",
       " 'Johnson_1866.txt',\n",
       " 'McKinley_1897.txt',\n",
       " 'Washington_1795.txt',\n",
       " 'Clinton_1999.txt',\n",
       " 'Adams_1797.txt',\n",
       " 'Clinton_1998.txt',\n",
       " 'Washington_1794.txt',\n",
       " 'Hayes_1880.txt',\n",
       " 'Johnson_1867.txt',\n",
       " 'Roosevelt_1944.txt',\n",
       " 'Eisenhower_1957.txt',\n",
       " 'Harrison_1891.txt',\n",
       " 'Bush_2005.txt',\n",
       " 'Roosevelt_1937.txt',\n",
       " 'Madison_1809.txt',\n",
       " 'Truman_1946.txt',\n",
       " 'Truman_1952.txt',\n",
       " 'Jefferson_1805.txt',\n",
       " 'Nixon_1972.txt',\n",
       " 'Nixon_1973.txt',\n",
       " 'Jefferson_1804.txt',\n",
       " 'Truman_1953.txt',\n",
       " 'Truman_1947.txt',\n",
       " 'Arthur_1884.txt',\n",
       " 'Wilson_1920.txt',\n",
       " 'Roosevelt_1936.txt',\n",
       " 'Bush_2004.txt',\n",
       " 'Harrison_1890.txt',\n",
       " 'Harrison_1892.txt',\n",
       " 'Reagan_1988.txt',\n",
       " 'Carter_1981.txt',\n",
       " 'Roosevelt_1908.txt',\n",
       " 'Roosevelt_1934.txt',\n",
       " 'Bush_2006.txt',\n",
       " 'Truman_1951.txt',\n",
       " 'Jefferson_1806.txt',\n",
       " 'Nixon_1971.txt',\n",
       " 'Nixon_1970.txt',\n",
       " 'Jefferson_1807.txt',\n",
       " 'Truman_1950.txt',\n",
       " 'Jackson_1829.txt',\n",
       " 'Bush_2007.txt',\n",
       " 'Roosevelt_1935.txt',\n",
       " 'Carter_1980.txt',\n",
       " 'Bush_2003.txt',\n",
       " 'Buren_1839.txt',\n",
       " 'Taylor_1849.txt',\n",
       " 'Arthur_1883.txt',\n",
       " 'Polk_1847.txt',\n",
       " 'Jefferson_1803.txt',\n",
       " 'Johnson_1966.txt',\n",
       " 'Nixon_1974.txt',\n",
       " 'Johnson_1967.txt',\n",
       " 'Jefferson_1802.txt',\n",
       " 'Polk_1846.txt',\n",
       " 'Arthur_1882.txt',\n",
       " 'Buren_1838.txt',\n",
       " 'Bush_2002.txt',\n",
       " 'Carter_1978.txt',\n",
       " 'Wilson_1918.txt',\n",
       " 'Taft_1909.txt',\n",
       " 'Johnson_1965.txt',\n",
       " 'Clinton_2000.txt',\n",
       " 'Hoover_1929.txt',\n",
       " 'Johnson_1964.txt',\n",
       " 'Jefferson_1801.txt',\n",
       " 'Polk_1845.txt',\n",
       " 'Arthur_1881.txt',\n",
       " 'Wilson_1919.txt',\n",
       " 'Carter_1979.txt',\n",
       " 'Bush_2001.txt']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now loop through all of them and write to the folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    lemmatize(in_path, out_path, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
